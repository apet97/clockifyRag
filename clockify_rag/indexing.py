"""Index building and loading for BM25 and FAISS."""

import hashlib
import json
import logging
import math
import os
import platform
import threading
import time
from collections import Counter
from typing import Optional

import numpy as np

from .chunking import build_chunks
from . import config
from .embedding import embed_texts, embed_local_batch, load_embedding_cache, save_embedding_cache
from .exceptions import BuildError
from .utils import (
    ALLOWED_CORPUS_FILENAME,
    build_lock,
    atomic_write_jsonl,
    atomic_save_npy,
    atomic_write_json,
    tokenize,
    compute_sha256,
)
from .metrics import get_metrics, MetricNames

logger = logging.getLogger(__name__)

# Global FAISS index with thread safety
_FAISS_INDEX = None
_FAISS_INDEX_PATH: Optional[str] = None
_FAISS_LOCK = threading.Lock()


def _try_load_faiss():
    """Try importing FAISS; returns None if not available."""
    try:
        import faiss

        return faiss
    except ImportError:
        logger.info("info: ann=fallback reason=missing-faiss")
        return None


def build_faiss_index(vecs: np.ndarray, nlist: int = 256, metric: str = "ip") -> object:
    """Build FAISS IVFFlat index (inner product for cosine on normalized vectors).

    Rank 22 optimization: macOS arm64 attempts IVFFlat with nlist=32 (small subset training)
    before falling back to FlatIP. This provides 10-50x speedup over linear search.
    """
    faiss = _try_load_faiss()
    if faiss is None:
        return None

    total_vecs = len(vecs)
    if total_vecs == 0:
        logger.info("FAISS: received empty vector matrix; returning None")
        return None

    dim = vecs.shape[1]
    vecs_f32 = np.ascontiguousarray(vecs.astype("float32"))

    if total_vecs < config.FAISS_IVF_MIN_ROWS:
        logger.info(
            "FAISS: using IndexFlatIP fallback for %d vectors (< %d IVF threshold)",
            total_vecs,
            config.FAISS_IVF_MIN_ROWS,
        )
        index = faiss.IndexFlatIP(dim)
        index.add(vecs_f32)
        return index

    # Detect macOS arm64 and optimize for M1/M2/M3 chips
    is_macos_arm64 = platform.system() == "Darwin" and platform.machine() == "arm64"

    if is_macos_arm64:
        # Rank 22: Try IVFFlat with smaller default nlist for M1 Macs.
        # Scale with corpus size to preserve accuracy on larger builds.
        dynamic_nlist = max(32, min(nlist, total_vecs // 20 or 32))
        m1_nlist = max(32, dynamic_nlist)
        m1_train_size = min(1000, len(vecs))

        logger.info(f"macOS arm64 detected: attempting IVFFlat with nlist={m1_nlist}, train_size={m1_train_size}")

        try:
            quantizer = faiss.IndexFlatIP(dim)
            index = faiss.IndexIVFFlat(quantizer, dim, m1_nlist, faiss.METRIC_INNER_PRODUCT)

            if len(vecs) >= m1_train_size:
                # Seed RNG for reproducible training (Rank 11)
                rng = np.random.default_rng(config.DEFAULT_SEED)
                train_indices = rng.choice(len(vecs), m1_train_size, replace=False)
                train_vecs = vecs_f32[train_indices]
            else:
                train_vecs = vecs_f32

            # Seed for deterministic training
            np.random.seed(config.DEFAULT_SEED)
            index.train(train_vecs)
            index.add(vecs_f32)

            logger.info(f"âœ“ Successfully built IVFFlat index on M1 (nlist={m1_nlist}, vectors={len(vecs)})")
            logger.info("  Expected speedup: 10-50x over linear search for similarity queries")

        except (RuntimeError, SystemError, OSError) as e:
            logger.warning(f"IVFFlat training failed on M1: {type(e).__name__}: {str(e)[:100]}")
            logger.info("Falling back to IndexFlatIP (linear search) for stability")
            index = faiss.IndexFlatIP(dim)
            index.add(vecs_f32)
    else:
        # Other platforms: use IVFFlat with standard nlist
        quantizer = faiss.IndexFlatIP(dim)
        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)

        train_size = min(20000, len(vecs))
        # Seed RNG for reproducible training (Rank 11)
        rng = np.random.default_rng(config.DEFAULT_SEED)
        train_indices = rng.choice(len(vecs), train_size, replace=False)
        train_vecs = vecs_f32[train_indices]

        # Seed for deterministic training
        np.random.seed(config.DEFAULT_SEED)
        index.train(train_vecs)
        index.add(vecs_f32)

    # Only set nprobe for IVF indexes (not flat indexes)
    if hasattr(index, "nprobe"):
        index.nprobe = config.ANN_NPROBE

    index_type = "IVFFlat" if hasattr(index, "nlist") else "FlatIP"
    logger.debug(f"Built FAISS index: type={index_type}, vectors={len(vecs)}")
    return index


def save_faiss_index(index, path: Optional[str] = None):
    """Save FAISS index to disk."""
    if index is None or path is None:
        return
    faiss = _try_load_faiss()
    if faiss:
        faiss.write_index(index, path)
        logger.debug(f"Saved FAISS index to {path}")


def load_faiss_index(path: Optional[str] = None):
    """Load FAISS index from disk with thread-safe lazy loading."""
    global _FAISS_INDEX, _FAISS_INDEX_PATH

    if path is None or not os.path.exists(path):
        return None

    abs_path = os.path.abspath(path)

    # Double-checked locking pattern for thread safety
    if _FAISS_INDEX is not None and _FAISS_INDEX_PATH == abs_path:
        return _FAISS_INDEX

    with _FAISS_LOCK:
        if _FAISS_INDEX is not None and _FAISS_INDEX_PATH == abs_path:
            return _FAISS_INDEX

        faiss = _try_load_faiss()
        if faiss:
            _FAISS_INDEX = faiss.read_index(path)
            _FAISS_INDEX_PATH = abs_path
            # Only set nprobe for IVF indexes (not flat indexes)
            if hasattr(_FAISS_INDEX, "nprobe"):
                _FAISS_INDEX.nprobe = config.ANN_NPROBE
            logger.debug(f"Loaded FAISS index from {path}")
            return _FAISS_INDEX
        return None


def get_faiss_index(path: Optional[str] = None):
    """Thread-safe getter for global FAISS index.

    FIX (Error #1): Single source of truth for FAISS index state.
    This function provides controlled access to the global index,
    preventing duplicate state across modules.

    Args:
        path: Optional path to load index from if not already loaded

    Returns:
        FAISS index object or None if not available
    """
    global _FAISS_INDEX, _FAISS_INDEX_PATH
    if path:
        abs_path = os.path.abspath(path)
        if _FAISS_INDEX is not None and _FAISS_INDEX_PATH == abs_path:
            return _FAISS_INDEX
        return load_faiss_index(path)
    return _FAISS_INDEX


def reset_faiss_index():
    """Reset global FAISS index (called after rebuild).

    FIX (Error #1): Centralized index reset to prevent stale references.
    """
    global _FAISS_INDEX, _FAISS_INDEX_PATH
    with _FAISS_LOCK:
        _FAISS_INDEX = None
        _FAISS_INDEX_PATH = None
        logger.debug("Reset global FAISS index cache")


# ====== BM25 ======
def build_bm25(chunks: list) -> dict:
    """Build BM25 index."""
    docs = [tokenize(c["text"]) for c in chunks]
    N = len(docs)
    df: Counter = Counter()
    doc_tfs: list[dict] = []
    doc_lens: list[int] = []
    for toks in docs:
        tf = Counter(toks)
        doc_tfs.append(tf)
        doc_lens.append(len(toks))
        for w in tf.keys():
            df[w] += 1
    avgdl = sum(doc_lens) / max(1, N)
    idf = {}
    for w, dfw in df.items():
        idf[w] = math.log((N - dfw + 0.5) / (dfw + 0.5) + 1.0)
    return {
        "idf": idf,
        "avgdl": avgdl,
        "doc_lens": doc_lens,
        "doc_tfs": [{k: v for k, v in tf.items()} for tf in doc_tfs],
    }


def bm25_scores(
    query: str, bm: dict, k1: Optional[float] = None, b: Optional[float] = None, top_k: Optional[int] = None
) -> np.ndarray:
    """Compute BM25 scores with optional early termination (Rank 24)."""
    if k1 is None:
        k1 = config.BM25_K1
    if b is None:
        b = config.BM25_B
    q = tokenize(query)
    idf = bm["idf"]
    avgdl = bm["avgdl"]
    doc_lens = bm["doc_lens"]
    doc_tfs = bm["doc_tfs"]

    # Rank 24: Early termination with Wand-like pruning
    # OPTIMIZATION: Lowered threshold from 1.5x to 1.1x for 2-3x speedup on medium/large corpora
    if top_k is not None and top_k > 0 and len(doc_lens) > top_k * 1.1:  # Was 1.5, now 1.1
        import heapq

        term_upper_bounds = {}
        for w in q:
            if w in idf:
                term_upper_bounds[w] = idf[w] * (k1 + 1)

        total_upper_bound = sum(term_upper_bounds.values())
        top_scores: list[tuple[float, int]] = []
        threshold = 0.0

        for i, tf in enumerate(doc_tfs):
            if not any(w in tf for w in q):
                continue

            if len(top_scores) >= top_k and total_upper_bound < threshold:
                continue

            dl = doc_lens[i]
            s = 0.0
            for w in q:
                if w not in idf:
                    continue
                f = tf.get(w, 0)
                if f == 0:
                    continue
                denom = f + k1 * (1 - b + b * dl / max(1.0, avgdl))
                s += idf[w] * (f * (k1 + 1)) / denom

            if len(top_scores) < top_k:
                heapq.heappush(top_scores, (s, i))
                if len(top_scores) == top_k:
                    threshold = top_scores[0][0]
            elif s > threshold:
                heapq.heapreplace(top_scores, (s, i))
                threshold = top_scores[0][0]

        scores = np.zeros(len(doc_lens), dtype="float32")
        for score, idx in top_scores:
            scores[idx] = score

        return scores

    # Original implementation: compute all scores
    scores = np.zeros(len(doc_lens), dtype="float32")
    for i, tf in enumerate(doc_tfs):
        dl = doc_lens[i]
        s = 0.0
        for w in q:
            if w not in idf:
                continue
            f = tf.get(w, 0)
            if f == 0:
                continue
            denom = f + k1 * (1 - b + b * dl / max(1.0, avgdl))
            s += idf[w] * (f * (k1 + 1)) / denom
        scores[i] = s
    return scores


# ====== BUILD FUNCTION ======
def build(md_path: str, retries=None):
    """Build knowledge base with atomic writes and locking."""
    md_path = os.path.expandvars(os.path.expanduser(str(md_path)))
    if os.path.basename(md_path) != ALLOWED_CORPUS_FILENAME:
        raise BuildError(f"Only {ALLOWED_CORPUS_FILENAME} is supported for ingestion.")
    if not os.path.isfile(md_path):
        raise BuildError(f"{md_path} not found")
    with build_lock():
        logger.info("=" * 70)
        logger.info("BUILDING KNOWLEDGE BASE")
        logger.info("=" * 70)
        metrics = get_metrics()
        metrics.increment_counter(MetricNames.INGESTIONS_TOTAL)
        ingest_start = time.time()
        logger.info(
            json.dumps(
                {
                    "event": "rag.ingest.start",
                    "md_path": md_path,
                    "backend": config.EMB_BACKEND,
                }
            )
        )

        logger.info("\n[1/4] Parsing and chunking...")
        chunks = build_chunks(md_path)
        logger.info(f"  Created {len(chunks)} chunks")
        atomic_write_jsonl(config.FILES["chunks"], chunks)

        logger.info(f"\n[2/4] Embedding with {config.EMB_BACKEND}...")
        emb_cache = load_embedding_cache()
        effective_retries = config.DEFAULT_RETRIES if retries is None else retries

        # Compute content hashes
        chunk_hashes = []
        cache_hits = []
        cache_miss_indices = []
        cache_changed = False

        for i, chunk in enumerate(chunks):
            chunk_hash = hashlib.sha256(chunk["text"].encode("utf-8")).hexdigest()
            chunk_hashes.append(chunk_hash)

            if chunk_hash in emb_cache:
                cache_hits.append(emb_cache[chunk_hash])
            else:
                cache_hits.append(None)
                cache_miss_indices.append(i)

        valid_hashes = set(chunk_hashes)
        stale_keys = [key for key in emb_cache.keys() if key not in valid_hashes]
        if stale_keys:
            for key in stale_keys:
                emb_cache.pop(key, None)
            cache_changed = True
            logger.info(f"  Pruned {len(stale_keys)} stale embedding cache entries")

        hit_rate = (len(chunks) - len(cache_miss_indices)) / len(chunks) * 100 if chunks else 0
        logger.info(f"  Cache: {len(chunks) - len(cache_miss_indices)}/{len(chunks)} hits ({hit_rate:.1f}%)")

        # Compute expected dimension based on current backend
        expected_dim = config.EMB_DIM_LOCAL if config.EMB_BACKEND == "local" else config.EMB_DIM_OLLAMA

        # Embed cache misses
        new_embeddings: np.ndarray = np.empty((0, expected_dim), dtype=np.float32)
        if cache_miss_indices:
            texts_to_embed = [chunks[i]["text"] for i in cache_miss_indices]
            logger.info(f"  Computing {len(texts_to_embed)} new embeddings...")

            if config.EMB_BACKEND == "local":
                new_embeddings = embed_local_batch(texts_to_embed, normalize=False)
            else:
                new_embeddings = embed_texts(texts_to_embed, retries=effective_retries)

            for i, idx in enumerate(cache_miss_indices):
                chunk_hash = chunk_hashes[idx]
                emb_cache[chunk_hash] = new_embeddings[i].astype(np.float32)
            cache_changed = True

        # Reconstruct full embedding matrix with dimension validation
        vecs_list: list = []
        new_emb_idx = 0
        for i in range(len(chunks)):
            if cache_hits[i] is not None:
                cached_emb = cache_hits[i]
                # Defensive check: validate cached embedding dimension
                if len(cached_emb) != expected_dim:
                    raise BuildError(
                        f"Cached embedding {i} has dimension {len(cached_emb)}, "
                        f"expected {expected_dim} for backend={config.EMB_BACKEND}. "
                        f"This should have been filtered by load_embedding_cache(). "
                        f"Try deleting {config.FILES['emb_cache']} and rebuilding."
                    )
                vecs_list.append(cached_emb)
            else:
                new_emb = new_embeddings[new_emb_idx]
                # Validate new embedding dimension
                if len(new_emb) != expected_dim:
                    raise BuildError(
                        f"New embedding {i} has dimension {len(new_emb)}, "
                        f"expected {expected_dim} for backend={config.EMB_BACKEND}. "
                        f"Check {config.EMB_BACKEND} configuration or model output."
                    )
                vecs_list.append(new_emb)
                new_emb_idx += 1

        # Final sanity check before array construction
        if vecs_list:
            first_dim = len(vecs_list[0])
            for idx, vec in enumerate(vecs_list):
                if len(vec) != first_dim:
                    raise BuildError(
                        f"Dimension mismatch at index {idx}: "
                        f"expected {first_dim}, got {len(vec)}. "
                        f"Cannot mix embeddings with different dimensions."
                    )

        vecs = np.array(vecs_list, dtype=np.float32)

        if cache_miss_indices or cache_changed:
            save_embedding_cache(emb_cache)

        # Normalize embeddings
        norms = np.linalg.norm(vecs, axis=1, keepdims=True)
        norms[norms == 0] = 1e-9
        vecs_n = (vecs / norms).astype("float32")
        atomic_save_npy(vecs_n, config.FILES["emb"])
        logger.info(f"  Saved {vecs_n.shape} embeddings (normalized)")

        # Write metadata
        meta_lines = [{"id": c["id"], "title": c["title"], "url": c["url"], "section": c["section"]} for c in chunks]
        atomic_write_jsonl(config.FILES["meta"], meta_lines)

        logger.info("\n[3/4] Building BM25 index...")
        bm = build_bm25(chunks)
        atomic_write_json(config.FILES["bm25"], bm)
        logger.info(f"  Indexed {len(bm['idf'])} unique terms")

        # Optional FAISS
        if config.USE_ANN == "faiss":
            try:
                logger.info("\n[3.1/4] Building FAISS ANN index...")
                faiss_index = build_faiss_index(vecs_n, nlist=config.ANN_NLIST)
                if faiss_index is not None:
                    # FIX: Reset cache BEFORE saving to prevent race condition
                    # where concurrent readers could get stale cached index
                    # between save and reset. After reset, readers will re-load
                    # from disk (getting either old or new version, both valid).
                    reset_faiss_index()
                    save_faiss_index(faiss_index, config.FILES["faiss_index"])
                    logger.info(f"  Saved FAISS index to {config.FILES['faiss_index']}")
            except Exception as e:
                logger.warning(f"  FAISS index build failed: {e}")

        # Write metadata
        logger.info("\n[3.6/4] Writing artifact metadata...")
        kb_sha = compute_sha256(md_path)
        index_meta = {
            "kb_sha256": kb_sha,
            "chunks": len(chunks),
            "emb_rows": int(vecs_n.shape[0]),
            "bm25_docs": len(bm["doc_lens"]),
            "gen_model": config.RAG_CHAT_MODEL,
            "emb_model": config.RAG_EMBED_MODEL if config.EMB_BACKEND == "ollama" else "all-MiniLM-L6-v2",
            "emb_backend": config.EMB_BACKEND,
            "ann": config.USE_ANN,
            "built_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        }
        atomic_write_json(config.FILES["index_meta"], index_meta)
        logger.info("  Saved index metadata")

        # Note: FAISS cache reset moved to before save_faiss_index() to prevent race condition

        duration_ms = (time.time() - ingest_start) * 1000
        metrics.observe_histogram(MetricNames.INGESTION_LATENCY, duration_ms)
        metrics.set_gauge(MetricNames.INDEX_SIZE, len(chunks))
        logger.info(
            json.dumps(
                {
                    "event": "rag.ingest.complete",
                    "md_path": md_path,
                    "chunks": len(chunks),
                    "duration_ms": round(duration_ms, 2),
                    "cache_hit_rate": round(hit_rate, 2) if chunks else 0.0,
                }
            )
        )

        logger.info("\n[4/4] Done.")
        logger.info("=" * 70)


def load_index(kb_path: Optional[str] = None):
    """Load all index artifacts with dimension and freshness validation.

    FIX: Validates that stored embeddings match the current config.EMB_BACKEND and config.EMB_DIM
    to prevent runtime crashes from dimension mismatches (e.g., switching from
    local 384-dim to ollama 768-dim without rebuilding).

    FIX: Validates knowledge base SHA256 hash to detect stale indexes when the
    knowledge base has been updated but the index hasn't been rebuilt.

    Args:
        kb_path: Optional path to knowledge base for freshness validation.
                 If provided, compares stored hash with current KB hash.

    Returns:
        dict with index artifacts, or None if validation fails (requiring rebuild)
    """
    if not os.path.exists(config.FILES["index_meta"]):
        logger.warning("[rebuild] index.meta.json missing")
        return None

    with open(config.FILES["index_meta"], encoding="utf-8") as f:
        meta = json.load(f)

    # Validate knowledge base freshness (warning only, not blocking)
    stored_kb_sha = meta.get("kb_sha256")
    if kb_path and stored_kb_sha:
        try:
            current_kb_sha = compute_sha256(kb_path)
            if current_kb_sha != stored_kb_sha:
                logger.warning("âš ï¸  Knowledge base has changed since index was built")
                logger.warning(f"   Stored hash:  {stored_kb_sha[:16]}...")
                logger.warning(f"   Current hash: {current_kb_sha[:16]}...")
                logger.warning("   ðŸ’¡ Consider rebuilding: ragctl ingest --input knowledge_helpcenter.md --force")
                # Store stale flag in meta for reporting
                meta["_stale"] = True
                meta["_current_kb_sha"] = current_kb_sha
        except Exception as e:
            logger.debug(f"Could not validate KB hash: {e}")

    # Validate backend compatibility
    stored_backend = meta.get("emb_backend")
    stored_model = meta.get("emb_model")

    if stored_backend and stored_backend != config.EMB_BACKEND:
        logger.error(f"âŒ Index backend mismatch: stored={stored_backend}, current={config.EMB_BACKEND}")
        logger.error(f"   Stored model: {stored_model}")
        logger.error(
            f"   Current model: {config.RAG_EMBED_MODEL if config.EMB_BACKEND == 'ollama' else 'all-MiniLM-L6-v2'}"
        )
        logger.error(f"   Expected dimension: {config.EMB_DIM}")
        logger.error("")
        logger.error("ðŸ’¡ Solution: Rebuild the index with the current backend:")
        logger.error("   python3 -m clockify_rag.cli_modern ingest --input knowledge_helpcenter.md --force")
        logger.error("")
        return None

    # Load chunks
    chunks = []
    with open(config.FILES["chunks"], encoding="utf-8") as f:
        for line in f:
            if line.strip():
                chunks.append(json.loads(line))

    # Load embeddings
    vecs_n = np.load(config.FILES["emb"])

    # Validate embedding dimensions
    # Compute expected dimension based on current backend
    expected_dim = config.EMB_DIM_LOCAL if config.EMB_BACKEND == "local" else config.EMB_DIM_OLLAMA
    stored_dim = vecs_n.shape[1] if len(vecs_n.shape) > 1 else 0

    if stored_dim != expected_dim:
        logger.error(
            f"âŒ Embedding dimension mismatch: stored={stored_dim}, expected={expected_dim} "
            f"(backend={config.EMB_BACKEND})"
        )
        logger.error("   This usually happens after switching embedding backends without rebuilding.")
        logger.error("")
        logger.error("ðŸ’¡ Solution: Rebuild the index:")
        logger.error("   python3 -m clockify_rag.cli_modern ingest --input knowledge_helpcenter.md --force")
        logger.error("")
        return None

    # Load BM25
    with open(config.FILES["bm25"], encoding="utf-8") as f:
        bm = json.load(f)

    # Optional FAISS
    faiss_index = None
    if config.USE_ANN == "faiss" and os.path.exists(config.FILES["faiss_index"]):
        faiss_index = load_faiss_index(config.FILES["faiss_index"])

    # Build chunk dict
    chunks_dict = {c["id"]: c for c in chunks}

    logger.info(f"Loaded {len(chunks)} chunks, {vecs_n.shape[0]} vectors, {len(bm['idf'])} terms")

    return {
        "chunks": chunks,
        "chunks_dict": chunks_dict,
        "vecs_n": vecs_n,
        "bm": bm,
        "faiss_index": faiss_index,
        "meta": meta,
    }


def index_is_fresh(kb_path: str) -> bool:
    """Return True when index artifacts match the current knowledge base and backend."""

    kb_path = os.path.expandvars(os.path.expanduser(str(kb_path)))
    if not os.path.exists(kb_path):
        return False

    required_files = [
        config.FILES["chunks"],
        config.FILES["emb"],
        config.FILES["meta"],
        config.FILES["bm25"],
        config.FILES["index_meta"],
    ]
    if not all(os.path.exists(path) for path in required_files):
        return False

    try:
        with open(config.FILES["index_meta"], encoding="utf-8") as f:
            meta = json.load(f)
    except Exception:
        return False

    stored_kb_sha = meta.get("kb_sha256")
    if not stored_kb_sha:
        return False

    try:
        current_kb_sha = compute_sha256(kb_path)
    except Exception as exc:
        logger.debug("Failed to compute KB SHA for freshness check: %s", exc)
        return False

    if current_kb_sha != stored_kb_sha:
        return False

    stored_backend = meta.get("emb_backend")
    if stored_backend and stored_backend != config.EMB_BACKEND:
        return False

    expected_model = config.RAG_EMBED_MODEL if config.EMB_BACKEND == "ollama" else "all-MiniLM-L6-v2"
    stored_model = meta.get("emb_model")
    if stored_model and stored_model != expected_model:
        return False

    return True
